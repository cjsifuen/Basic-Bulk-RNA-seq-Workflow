#snakemake-demo-rnaseq
#Christopher Sifuentes sifuentescj@gmail.com

#import modules
from __future__ import print_function, absolute_import, division
from argparse import Namespace
import collections
from collections import defaultdict
import csv
import fnmatch
from functools import partial
from functools import reduce
import glob
import hashlib
import os
from os.path import basename
from os.path import isfile
from os.path import join
from os.path import splitext
import shutil
import sys
import subprocess
import yaml
import snakemake


# define SNKDIR
SNK_DIR = os.path.dirname(srcdir("Snakefile"))

# set configuration file
configfile: os.path.join(SNK_DIR,"resources/config.yaml")

# define directories
INPUT_DIR = os.path.join(config['input_dir']['fastq'],'')
SCRIPT_DIR = os.path.join(SNK_DIR,'scripts','')
OUT_DIR = os.path.join(config['out_dir'],'')
QC_DIR = os.path.join(OUT_DIR, 'QC','')
TRIM_DIR = os.path.join(OUT_DIR, 'TRIM', '')
ALN_DIR = os.path.join(OUT_DIR, 'ALIGN', '')
COUNTS_DIR = os.path.join(OUT_DIR, 'COUNTS', '')
DIFFEX_DIR = os.path.join(OUT_DIR, 'DIFFEX','')

# grab read info
SUFFIX = config['read_info']['fastq_suffix'] + '.gz'
R1_SUFFIX = config['read_info']['r1_suffix'] + '.' + SUFFIX

#define lists of files and sample basenames
FILES = [os.path.basename(x) for x in glob.glob(INPUT_DIR + '*' + SUFFIX)]
FILES_BASE = [os.path.basename(x).split('.'+ SUFFIX)[0] for x in glob.glob(INPUT_DIR + '*' + SUFFIX)]
SAMPLES = [os.path.basename(x).split(R1_SUFFIX)[0] for x in fnmatch.filter(FILES, '*' + R1_SUFFIX)]

#define final outputs
rule all:
    input:
        [expand('{directory}{sample}{extension}',
               directory = QC_DIR,
               sample = FILES_BASE,
               extension = '_fastqc.zip'),
        expand('{directory}{sample}{extension}',
               directory = TRIM_DIR,
               sample = SAMPLES,
               extension = ['_val_1.fq', '_val_2.fq']),
        expand('{directory}{sample}{extension}',
               directory = ALN_DIR,
               sample = SAMPLES,
               extension = 'Aligned.sortedByCoord.out.bam'),
        COUNTS_DIR + 'counts.txt',
        COUNTS_DIR + 'counts_fixed.txt',
        expand('{directory}{prefix}{extension}',
                        directory=DIFFEX_DIR,
                        prefix=config['diffex_info']['prefix'],
                        extension=['_normCounts.txt','_results.txt','_sigdiff.txt','_vstCounts.txt'])]

#fastqc
rule fastqc:
    input:
        fastq = INPUT_DIR + '{sample}' + '.' + SUFFIX
    output:
        fastq = QC_DIR + '{sample}_fastqc.zip'
    params:
        qc_dir = QC_DIR,
        format = 'fastq',
    conda:
        'envs/fastqc_env.yml'
    threads:
        config['thread_info']['fastqc']
    shell:
        """
        mkdir -p {params.qc_dir}
        fastqc \
        --noextract \
        -f {params.format} \
        -o {params.qc_dir} \
        -t {threads} \
        {input.fastq}
        """

#trim_galore
rule trim_galore:
    input:
        r1 = INPUT_DIR + '{sample}_1' + '.' + SUFFIX,
        r2 = INPUT_DIR + '{sample}_2' + '.' + SUFFIX,
    output:
        r1 = TRIM_DIR + '{sample}_val_1.fq',
        r2 = TRIM_DIR + '{sample}_val_2.fq',
    conda:
        'envs/trim_galore_env.yml'
    params:
        length = config['trim_info']['length'],
        quality = config['trim_info']['quality'],
        base = '{sample}',
        out_dir = TRIM_DIR
    shell:
        """
        trim_galore \
        -q {params.quality} \
        --length {params.length} \
        --basename {params.base} \
        -o {params.out_dir} \
        --dont_gzip \
        --paired {input.r1} {input.r2}
        """

#star
rule star:
    input:
        r1 = TRIM_DIR + '{sample}_val_1.fq',
        r2 = TRIM_DIR + '{sample}_val_2.fq'
    output:
        bam = ALN_DIR + '{sample}Aligned.sortedByCoord.out.bam',
    conda:
        'envs/star_env.yml'
    params:
        out_prefix = ALN_DIR + '{sample}',
        index = config['input_dir']['genome_fasta'],
        gtf = config['input_dir']['genome_gtf']
    threads:
        config['thread_info']['align'],
    shell:
        """
        STAR \
        --genomeDir {params.index} \
        --readFilesIn {input.r1} {input.r2} \
        --sjdbGTFfile {params.gtf} \
        --outFileNamePrefix {params.out_prefix} \
        --runThreadN {threads} \
        --outSAMattributes Standard \
        --outSAMtype BAM SortedByCoordinate \
        --outFilterMismatchNmax 999 \
        --alignSJoverhangMin 8 \
        --alignSJDBoverhangMin 1 \
        --outFilterMismatchNoverReadLmax 0.04 \
        --alignIntronMin 20 \
        --alignIntronMax 1000000 \
        --alignMatesGapMax 1000000 \
        --sjdbScore 1
        """

#featureCounts
rule featureCounts:
    input:
        bams = sorted(expand('{directory}{sample}{extension}',
                      directory=ALN_DIR,
                      sample=SAMPLES,
                      extension='Aligned.sortedByCoord.out.bam')),
    output:
        counts = COUNTS_DIR + 'counts.txt',
        tmp = temp(COUNTS_DIR + 'counts.tmp'),
    conda:
        'envs/subread_env.yml'
    params:
        strand = config['count_info']['strand'],
        gtf = config['input_dir']['genome_gtf']
    threads:
        config['thread_info']['counts']
    shell:
        """
        featureCounts \
        -O \
        -p \
        -B \
        -C \
        -T {threads} \
        -s {params.strand} \
        -a {params.gtf} \
        -o {output.tmp} \
        {input.bams}

        sed '/^#/d' {output.tmp} | cut -f 1,7- > {output.counts}
        """

#clean couts
rule clean_counts:
    input:
        counts = COUNTS_DIR + 'counts.txt',
    output:
        counts = COUNTS_DIR + 'counts_fixed.txt',
    run:
        #import modules
        import pandas as pd
        import os

        #read in counts file
        counts_df = pd.read_csv(filepath_or_buffer=input.counts, sep='\t', header=0)

        #grab column names, remove path and extension to get desired basenames of files
        fixed_names = [os.path.basename(x).split('Aligned.sortedByCoord.out.bam')[0] for x in counts_df.columns]

        #reassign column values of df
        counts_df.columns = fixed_names

        #write out to fixed file
        counts_df.to_csv(path_or_buf=output.counts, sep = '\t', index=False, header=True)

#DESeq2
rule deseq2:
    input:
        counts = COUNTS_DIR + 'counts_fixed.txt'
    output:
        diffex = expand('{directory}{prefix}{extension}',
                        directory=DIFFEX_DIR,
                        prefix=config['diffex_info']['prefix'],
                        extension=['_normCounts.txt','_results.txt','_sigdiff.txt','_vstCounts.txt'])
    params:
        out_prefix = DIFFEX_DIR + config['diffex_info']['prefix'],
        script = SCRIPT_DIR + 'DESeq2.R',
        metadata = config['diffex_info']['metadata']
    shell:
        """
        Rscript {params.script} {params.metadata} {input.counts} {params.out_prefix}
        """